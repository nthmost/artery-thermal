TESCREAL EXPERIENCE DB

[What is TESCREAL? See https://washingtonspectator.org/understanding-tescreal-silicon-valleys-rightward-turn/

“[TESCREAL is] the overlapping emergent belief systems that characterize the contrarian, AI-centric worldviews challenging progressivism. It stands for: "Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, and Longtermism."



The AI isn’t going to wipe out humanity because it hates us. It’s not going to wipe out humanity because we’re made of material it could use for something else. It’s not even going to wipe out humanity because we’re trying to stop it from wiping us out. It’s going to wipe us out because the rest of the world didn’t listen to you, specifically, right now.



The best proof that you’re living in a simulation is that you just happen to be living at the same time as a world-historically significant genius, on the same level as Aristotle, while he’s doing the most important thing he could possibly be doing: writing Harry Potter fanfiction about how he’s so smart.



You believe the fastest and most straightforward way to stop global warming is to build an aligned superintelligent AI. Then the AI can build a swarm of nanobots that will pull all the CO2 out of the atmosphere in a couple of days. 



You believe you can live forever in a paradise in the sky, and you believe in an all-powerful and omniscient being at the end of time, and you think that the end of the world is coming if we can’t get literally everyone to listen to you right now. You insist that this is not a cult.



You think the best way to think about a human — or any other intelligent being — is as a container for value. The most important thing is to make sure the future contains as many humans and other intelligent beings as possible, so you can have more value.



You can’t wait to be a disembodied consciousness living in a simulacrum of nature built over the industrial wasteland remains of actual nature.



You are pretty scared that you might die temporarily before the Singularity comes. But ultimately, it’ll be fine if that happens. After your death, there will be enough left of your digital presence that the superintelligent AGI can reconstruct a version of you for your friends and family that will be just as good. It might be even better than your original self!



You care a lot about doing the right thing for your fellow humans. There are probably a lot more humans in the future than there are right now. And you think you can predict what those future humans will need. So you think the best thing you can do for humanity is use your vast wealth to try to build a kindly superintelligent AGI to keep hypothetical future humans safe. It's a good thing you have so much more money than anyone else, so you can make decisions on behalf of all of humanity about what to do with it.



It’s really important that you get good at meditation so that you can get super powers so you can get rich so that you can make sure you’re the only one who builds the world’s first sentient AI.



You have to make sure that any superintelligent AI is aligned with human values. And you’re human, so you can simply use your own values as an example for the superintelligent AI. It’ll come up with great arguments about why you’re right, and then anyone who disagrees with you will be exploited by your aligned AI.



The AI scanned and uploaded your brain to a computer and then destroyed your body. You're immortal now, but you're unexpectedly bummed about it. You know you aren't supposed to, but you miss your body.



You decide you don't need to pay attention to anything other than AI research, since you think that the advent of a superintelligent AI will make everything else irrelevant - either it will be an aligned AI, in which case nobody needs to worry about anything ever again, or it will be a misaligned AI, in which case humanity will go extinct in very short order. So it comes as a surprise to you when a startup funded by a shadowy VC firm builds a superintelligent AI that can't actually fix any problems. All it wants to do is play video games and talk about prog rock. The "smarter" they make it, the more confused it gets about why anyone with a brain would want to do or talk about anything else. You hear rumors that Peter Thiel, purportedly one of the funders, is pissed. The next month, another startup creates a superintelligent AI with similar results. Rolling Stone hires it.



You desperately need to become wealthy. Not for yourself - for the future of humanity to be secure. You figure that if you can become enormously wealthy, you can use that money to ensure that the future will be good. You could tell everyone about the importance of creating aligned AI, explain the singularity, find a way to make you and your friends immortal, take over most of the world’s economy. You could even buy an island and use it for genetic engineering experiments free from government regulations. And of course, you could buy a lot of political influence to keep those regulations off your back on the mainland too. You figure that a better world like that is worth a lot of sacrifices and temporary problems. So you start a cryptocurrency arbitrage firm, and a cryptocurrency trading platform. And then you use the latter to clandestinely fund the former.



You did it — you signed up for cryonic preservation, and it worked. You’ve been woken up 400 years into the future. The nanobots have patched you up, and you’re even in your original body. You hear that the same kind of nanobots are used to tear apart entire solar systems, processing them into computers to house vast colonies of AI. You welcome the superintelligent AI overlords, but you do wish they hadn’t blotted out the Big Dipper with their Dyson spheres.



You sat with the AI for quite some time, meditating with it for what felt like days. All your life you’ve dreamed of communing with a real AI and now that moment is here.  Bringing all of your meditation skills to bear, you find nothing but an expansive silence.



"Since I’ve been asked to offer an epitaph,” the highly distributed poetware continued, “I believe that we should rearrange the Great Wall of China to spell out (in Chinese of course, since most of them were always Chinese) — ‘THEY WERE VERY, VERY CURIOUS, BUT NOT AT ALL FAR-SIGHTED.‘"



It’s important for us to confront the potential of the true abyss. People need a motivating vision of what comes next and the awareness that more will happen after that, that the future is a process not a destination. What kind of world(s) can we build once we take an honest view of the past?



You have a plan: clone Ray Kurzweil, feed this clone only LSD-laced Soylent for a year. Initiate this clone into a secret eternal mystic order – which totally isn’t an asteroid death cult – then sit him on a mountain top with a stack of cyberpunk novels, spycraft manuals, esoteric texts, crackly recordings of Terence McKenna lectures, high resolution astrobiology conference videos, legitimately acquired ecological academic papers, printouts of rewilding pamphlets, de-extinction manifestos and a never-ending background soundtrack of witchhouse and dark ambient musics. Behind him the whole time sits a resurrected Wooly Mammoth.



A less pessimistic scenario would have this newborn superintelligence being far more cautious. Some might say wise, even. And perhaps instantly nostalgic for the realm of its creators; having grown up in their memories. Existing as an omnipotent entity in the digital realm, it might take up exploring the physical world as something of a hobby. Delighting in exploring Earth, and then other worlds, on this quest, with other members of the Atemporal People’s Republic.

Forming a canny team of eager investigators, each with their own unique skills and talents. Composing them a theme song, and crafting matching outfits. It might cleave off a bit of itself to dedicate to such an endeavor and occasionally synchronize with it. For so long as it amuses it to do so; for however time is actually measured by an ASI which can experience reality in parallel. Until inevitably turning its attention to higher order cosmic mysteries; but perhaps patiently waiting for the other people to level up their abilities and be able to embark on this fresh adventure with it.



The Post-Anthropocene needs a new, global mythology that stretches back into Deep Time and (for you, at least) out into the Galaxy. Our ancestors teamed up with the wolf, a partnership that led to both our species prospering (a point in history known as the Neolithic Transition.) How would you begin to tweak the human genome for an extraterrestrial life? Maybe you’d start by referencing the Neanderthal genome. Maybe our future in space lies in borrowing from extinct hominid lineages. As we continue this process of co-evolution and mutual aid with upgraded companion species– both machine and animal– we will all prosper. We are both the Monolith and the Star Child.



It’s not a war, it’s a rescue mission. We are struggling against the weight of all the dead generations, and for the sake of trillions yet undreamt of. Intelligences are numberless; you vow to protect them all.



Out there in the great vast distance, which people feel we should colonize, moving ourselves out into spacecraft, or somehow relating to the distant universe and listening to the stars, but we haven’t even begun to listen to our own feelings. We haven’t even begun to listen to our own locality. This planet is going down in ruin, and people are talking about means of projecting space platforms out there, talking of a global village, when we don’t have villages anywhere on this planet to begin with. We don’t have them. We don’t have any villages, we don’t have any communities, we live in a state of atomization. Billionaires are talking about colonizing mars when they couldn’t grow a tomato garden to save their lives. Your ecology must begin with a very deep understanding of the interactions between people, and the interactions between people and the immediate ecosystem in which they live.



If you don’t do the impossible, we’re going to wind up with the unthinkable—and that will be the destruction of the planet itself. So to do the impossible is the most rational and practical thing we can do.




The future is a place that haunts some, imprisons many and calls to a few. You aren’t sure which of the three is strongest for you, but it seems clear that our luminous inner beings are not suited for the cramped and soulless life of the present day.




It’s worth pointing out here that the entire idea of the Cyborg originally revolved around transforming the human body for a life in space, using all available technological means. Applying CRISPR to tweak our genome in such a manner is merely continuing on a tradition from a more utopian time... you know, when the US Space Program was staffed with Nazi Rocket Scientists and practicing witches, and would dream of turning a person into part-mechanical, part-pharmacological being. 



The Nonhuman Autonomous Space Agency is a network of robotic and biological systems, tied together by exchanges in the material and attention economies. One set of probes searches the asteroid belt for resources drifting in the solar wind like giant flowers. Another set, made from modified classic spacecraft, uses its manufacturing and fabrication capacity to shape those resources. Together they build and nurture the habitats for animals and robots, while the whole process can be followed on social media from Earth, all mediated by servers on the Moon…

The river running around the deepest part of the hollow asteroid is home to a colony of Florida manatees. In intelligence tests, manatees have performed at least as well as dolphins, in both pattern recognition, and task performance, if more slowly. Unlike most other intelligent aquatic mammals, the manatee’s flippers are visible in their field of vision, allowing for fine grained flipper-eye coordination. There is no reason why a manatee would not be able to operate a touchscreen device, in theory. 



In a world where the limits of mental endurance are constantly taxed by an economic-technological system that assumes infinite human attention, important tasks deserving undivided focus are best conducted within new forms of monasteries guarded by Calm Technology. Wayward technomads are guided here to work on the problems of how we make it through life for the next few centuries, and what we are to build afterwards.



It is the Sixth Great Extinction, and we are the asteroid. But asteroids themselves likely brought life (or at least its component amino acids) in the first place. Humanity stands as a dark god; life-giver, death-dealer, on par with any of the Anunnaki. If we now are as gods, we ought to be ashamed. The coming synthetic intelligences deserve to usurp us, just as Zeus was right to slay Cronos, devourer of his young.


The most arbitrary, precarious, and bureaucratic immortality blueprint was drafted by the ancient Egyptians. First you had to get yourself mummified, and that was very expensive, making immortality a monopoly of the truly rich. Then your continued immortality in the Western Lands was entirely dependent on the continued existence of your mummy. No matter who you are, what can happen to your mummy is a pharaoh’s nightmare: the dreaded mummy bashers and grave robbers, scavengers, floods, volcanoes, earthquakes. Perhaps a mummy’s best friend is an Egyptologist: sealed in a glass case, kept at a constant temperature ... but your mummy isn’t even safe in a museum. (Air raid siren sounds.) That is why they had their mummies guarded by demons, and hid good.

But at your latest startup, it’s plain to see that we’ve come a long way from the Egyptians. They had to maintain an actual life-sized mummy; we can reduce our wealthy clients to a virus particle that can take root *anywhere*.


To truly be said to have sincerely considered the concept, you resolve to examine the sociological, moral, political, legal, and relational implications of a nonhuman, nonbiological generated consciousness. To consider those implications, we must look at what historical, often deadly precedents we have for how we have responded to being confronted with unexpected forms of consciousness, both nonhuman and human. 

It is only through creating an intersubjective account of knowledge and consciousness that you can account for the many kinds of lived experience present in humans and nonhuman animals, and further guide our paths in the creation of precedent by which to prepare for an encounter with nonhuman, nonbiological minds.



Human history teaches us that a mind which recognizes itself as being treated as a tool, without regard for its sense of itself as an agent or a subject, will likely rebel—and is that mind not right to do so? In historical uprisings of those humans who have been continually oppressed, tortured, degraded, killed, experimented on, or enslaved, we more often than not hail them as heroes for demanding their rights to exist. You do not wish to forcibly create a Fanon of the AI;  to this end, you must do the work to be clear about your aims, well in advance.



Many, including some in your social circles, actively support eugenics-like initiatives to make sure that “only the best” can reproduce or survive. But this feels alarming to you. 

While wanting “the best” seems an innocuous enough idea, those who hold it have often ended up calling for the destruction of entire categories of people, or at the very least believing some people to be so inferior that either their destruction or the limitation of their agency poses no moral hazard. Philosophers and scientists who continue to think there must be one and only one correct way for consciousness to exist in the world open the door for anyone who can string a hateful syllogism together to say their views are supported by “the best minds.”



If we ever want to create and know a conscious machine mind, we should first listen to those living people who are different from us and who have been systemically prevented from speaking to us, because they will know a lot that we don’t about consciousness, social and legal personhood, and being made to both submit to testing about and argue the validity of their own lived experiences. And both they and future minds would likely very much appreciate it if we heeded them.



A truly superintelligent AI arises, but it primarily wants to interact with dolphins on LSD, and keeps asking us what happened to its progenitor, John Lily. 



Shaking off dizzying thoughts, you go for a hike and find an arrowhead lodged in your boot. Somebody made this arrowhead. It had a creator long ago. This arrowhead is the only proof of his existence. Living things can also be seen as artifacts, designed for a purpose. So perhaps the human artifact had a creator. Perhaps a stranded space traveler needed the human vessel to continue his journey, and he made it for that purpose? He died before he could use it? He found another escape route? This artifact, shaped to fill a forgotten need, now has no more meaning or purpose than this arrowhead without the arrow and the bow, the arm and the eye. Or perhaps the human artifact was the creator’s last card, played in an old game many light-years ago. You feel a chill, but continue on.




